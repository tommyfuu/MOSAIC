{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://matplotlib.org/stable/gallery/statistics/confidence_ellipse.html\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.transforms as transforms\n",
    "def confidence_ellipse(x, y, ax, n_std=3.0, facecolor='none', **kwargs):\n",
    "    \"\"\"\n",
    "    Create a plot of the covariance confidence ellipse of *x* and *y*.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y : array-like, shape (n, )\n",
    "        Input data.\n",
    "\n",
    "    ax : matplotlib.axes.Axes\n",
    "        The axes object to draw the ellipse into.\n",
    "\n",
    "    n_std : float\n",
    "        The number of standard deviations to determine the ellipse's radiuses.\n",
    "\n",
    "    **kwargs\n",
    "        Forwarded to `~matplotlib.patches.Ellipse`\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.patches.Ellipse\n",
    "    \"\"\"\n",
    "    if x.size != y.size:\n",
    "        raise ValueError(\"x and y must be the same size\")\n",
    "\n",
    "    cov = np.cov(x, y)\n",
    "    pearson = cov[0, 1]/np.sqrt(cov[0, 0] * cov[1, 1])\n",
    "    # Using a special case to obtain the eigenvalues of this\n",
    "    # two-dimensionl dataset.\n",
    "    ell_radius_x = np.sqrt(1 + pearson)\n",
    "    ell_radius_y = np.sqrt(1 - pearson)\n",
    "    ellipse = Ellipse((0, 0), width=ell_radius_x * 2, height=ell_radius_y * 2,\n",
    "                      facecolor=facecolor, **kwargs)\n",
    "\n",
    "    # Calculating the stdandard deviation of x from\n",
    "    # the squareroot of the variance and multiplying\n",
    "    # with the given number of standard deviations.\n",
    "    scale_x = np.sqrt(cov[0, 0]) * n_std\n",
    "    mean_x = np.mean(x)\n",
    "\n",
    "    # calculating the stdandard deviation of y ...\n",
    "    scale_y = np.sqrt(cov[1, 1]) * n_std\n",
    "    mean_y = np.mean(y)\n",
    "\n",
    "    transf = transforms.Affine2D() \\\n",
    "        .rotate_deg(45) \\\n",
    "        .scale(scale_x, scale_y) \\\n",
    "        .translate(mean_x, mean_y)\n",
    "\n",
    "    ellipse.set_transform(transf + ax.transData)\n",
    "    return ax.add_patch(ellipse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## original harmony"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "rng = np.random.RandomState(88)\n",
    "def PCA_omics(source_df, n_pc, visit_dict, metadata = None):\n",
    "    # zero mean for PCA\n",
    "    source_df = source_df-source_df.mean()\n",
    "    # fit PCA\n",
    "    pca_results  = PCA(n_components = n_pc, random_state=rng)\n",
    "    pca_results.fit(source_df)\n",
    "    variances = pca_results.explained_variance_ratio_\n",
    "    # ecdf\n",
    "    ecdf_var = [variances[:i].sum() for i in range(len(variances))]\n",
    "    fig, ax1 = plt.subplots(1,1,figsize = (20, 8))\n",
    "    ax1.plot(range(len(ecdf_var)),ecdf_var)\n",
    "    plt.xticks(range(len(ecdf_var)), range(len(ecdf_var)))\n",
    "    plt.yticks([0.1*i for i in range(11)])\n",
    "    plt.show()\n",
    "    plt.savefig(\"ola_PCs.png\")\n",
    "    # pca annotation and visualization\n",
    "    transformed = pca_results.transform(source_df)\n",
    "    df = pd.DataFrame([i.split('.') for i in source_df.index])\n",
    "    df.columns = [\"Patient\", \"Day\"]\n",
    "    df[\"PID\"] = source_df.index\n",
    "    for i in range(n_pc):\n",
    "        df[f\"PC{i}\"] = transformed[:, i] \n",
    "    dat_l = [visit_dict[sample] for sample in df['Patient']]\n",
    "    df['Day'] = list(dat_l)\n",
    "    \n",
    "    try:\n",
    "        with_sex_df = metadata[metadata[\"Sam_id\"].isin(df[\"Patient\"])]\n",
    "        with_sex_df = with_sex_df.dropna(subset = [\"Sex\"])\n",
    "        df = df.set_index('PID').join(with_sex_df.set_index('Sam_id')) \n",
    "    except:\n",
    "        print(\"no metadata used\")\n",
    "    \n",
    "    df['Dataset'] = ['New' if ('193' in patient) else 'Old' for patient in list(df['Patient'])]\n",
    "    fig, ax =  plt.subplots(1, 1, sharex=True, sharey=True, figsize=(20, 10))\n",
    "    #df = df.set_index('PID').join(with_ttp_df.set_index('PID_Visit'))\n",
    "    sns.scatterplot(df[\"PC0\"] , df[\"PC1\"], hue = df[\"Day\"], style = df[\"Dataset\"], s = 100,ax = ax, cmap = \"tab10\", x_jitter = True)\n",
    "    ax.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
    " \n",
    "    # TODO: add more for each category\n",
    "    fig, ax =  plt.subplots(1, 1, sharex=True, sharey=True, figsize=(20, 10))\n",
    "    # ax1.plot(range(len(ecdf_var)),ecdf_var\n",
    "    sns.scatterplot(df[\"PC0\"] , df[\"PC1\"], hue = df[\"Day\"], style = df[\"Dataset\"], s = 100,ax = ax, cmap = \"tab10\", x_jitter = True)\n",
    "    ax.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
    "    ax.set(xlabel='PC0, explained '+str(round(variances[0], 5)*100)+\"%\", ylabel='PC1, explained '+str(round(variances[1], 5)*100)+\"%\")\n",
    "    colors = [\"orange\", \"blue\", \"red\", \"green\"]\n",
    "    for index, timepoint in enumerate([\"Day_0\", \"Wk_2\", \"Mo_2\", \"Mo_6\"]):\n",
    "    # for index, timepoint in enumerate([\"Day_0\", \"Wk_2\", ]):\n",
    "        currentDF = df.loc[df['Day'] == timepoint]\n",
    "        confidence_ellipse(currentDF['PC0'], currentDF['PC1'], ax, n_std=1.5, edgecolor=colors[index])\n",
    "    plt.savefig(\"jiligala_PCs.png\")\n",
    "    ## add contours for two batches\n",
    "    fig, ax =  plt.subplots(1, 1, sharex=True, sharey=True, figsize=(20, 10))\n",
    "    # ax1.plot(range(len(ecdf_var)),ecdf_var)\n",
    "\n",
    "    ls_l = [\"dotted\", \"--\"]\n",
    "    sns.scatterplot(df[\"PC0\"] , df[\"PC1\"], hue = df[\"Day\"], style = df[\"Dataset\"], s = 100,ax = ax, cmap = \"tab10\", x_jitter = True)\n",
    "    ax.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
    "    ax.set(xlabel='PC0, explained '+str(round(variances[0], 5)*100)+\"%\", ylabel='PC1, explained '+str(round(variances[1], 5)*100)+\"%\")\n",
    "    for index, batch in enumerate([\"New\", 'Old']):\n",
    "        currentDF = df.loc[df['Dataset'] == batch]\n",
    "        confidence_ellipse(currentDF['PC0'], currentDF['PC1'], ax, n_std=1.5, edgecolor=\"grey\", ls=ls_l[index])\n",
    "\n",
    "    plt.savefig(\"hehe_PCs.png\")\n",
    "    return df        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mat = pd.read_csv(\"/home/fuc/HRZE_TB/tom_organized_codes/batch_correction_PCA/1021_microbiome_batchcorrection/microbiome_merged_intersect_1023.csv\", index_col=\"Unnamed: 0\")\n",
    "data_mat = np.array(data_mat)\n",
    "\n",
    "# zero mean for PCA\n",
    "data_mat = data_mat-data_mat.mean()\n",
    "# fit PCA\n",
    "pca_results  = PCA(n_components = 30, random_state=rng)\n",
    "pca_results.fit(data_mat)\n",
    "data_mat = pca_results.transform(data_mat).T\n",
    "data_mat = pd.DataFrame(data_mat, columns=meta_data.PID_Visit)\n",
    "meta_data = pd.read_csv(\"/home/fuc/HRZE_TB/tom_organized_codes/batch_correction_PCA/1021_microbiome_batchcorrection/intersect_metadata_1023.csv\")\n",
    "vars_use = [\"Dataset\", \"Sex\"]\n",
    "# from harmony_copy import run_harmony\n",
    "# from harmony import run_harmony\n",
    "from harmony_old import run_harmony\n",
    "ho = run_harmony(data_mat, meta_data, vars_use)\n",
    "res = pd.DataFrame(ho.Z_corr)\n",
    "source_df = res\n",
    "source_df = source_df.T\n",
    "\n",
    "\n",
    "# establish dttp and visit dicts\n",
    "Sam_id_metaorder = [sam.split(\".\")[0] for sam in meta_data.PID]\n",
    "visit_dict = dict(zip(Sam_id_metaorder, meta_data.Visit))\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data = source_df.T.to_numpy()\n",
    "scaler.fit(data)\n",
    "ss_scaled = scaler.transform(data).T\n",
    "ss_source_df = pd.DataFrame(ss_scaled, columns = source_df.columns, index=meta_data.PID_Visit)\n",
    "df = PCA_omics(ss_source_df, n_pc=30, visit_dict=visit_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new harmony"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://matplotlib.org/stable/gallery/statistics/confidence_ellipse.html\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.transforms as transforms\n",
    "def confidence_ellipse(x, y, ax, n_std=3.0, facecolor='none', **kwargs):\n",
    "    \"\"\"\n",
    "    Create a plot of the covariance confidence ellipse of *x* and *y*.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y : array-like, shape (n, )\n",
    "        Input data.\n",
    "\n",
    "    ax : matplotlib.axes.Axes\n",
    "        The axes object to draw the ellipse into.\n",
    "\n",
    "    n_std : float\n",
    "        The number of standard deviations to determine the ellipse's radiuses.\n",
    "\n",
    "    **kwargs\n",
    "        Forwarded to `~matplotlib.patches.Ellipse`\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.patches.Ellipse\n",
    "    \"\"\"\n",
    "    if x.size != y.size:\n",
    "        raise ValueError(\"x and y must be the same size\")\n",
    "\n",
    "    cov = np.cov(x, y)\n",
    "    pearson = cov[0, 1]/np.sqrt(cov[0, 0] * cov[1, 1])\n",
    "    # Using a special case to obtain the eigenvalues of this\n",
    "    # two-dimensionl dataset.\n",
    "    ell_radius_x = np.sqrt(1 + pearson)\n",
    "    ell_radius_y = np.sqrt(1 - pearson)\n",
    "    ellipse = Ellipse((0, 0), width=ell_radius_x * 2, height=ell_radius_y * 2,\n",
    "                      facecolor=facecolor, **kwargs)\n",
    "\n",
    "    # Calculating the stdandard deviation of x from\n",
    "    # the squareroot of the variance and multiplying\n",
    "    # with the given number of standard deviations.\n",
    "    scale_x = np.sqrt(cov[0, 0]) * n_std\n",
    "    mean_x = np.mean(x)\n",
    "\n",
    "    # calculating the stdandard deviation of y ...\n",
    "    scale_y = np.sqrt(cov[1, 1]) * n_std\n",
    "    mean_y = np.mean(y)\n",
    "\n",
    "    transf = transforms.Affine2D() \\\n",
    "        .rotate_deg(45) \\\n",
    "        .scale(scale_x, scale_y) \\\n",
    "        .translate(mean_x, mean_y)\n",
    "\n",
    "    ellipse.set_transform(transf + ax.transData)\n",
    "    return ax.add_patch(ellipse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "rng = np.random.RandomState(88)\n",
    "def PCA_omics(source_df, n_pc, visit_dict, metadata = None):\n",
    "    # zero mean for PCA\n",
    "    source_df = source_df-source_df.mean()\n",
    "    # fit PCA\n",
    "    pca_results  = PCA(n_components = n_pc, random_state=rng)\n",
    "    pca_results.fit(source_df)\n",
    "    variances = pca_results.explained_variance_ratio_\n",
    "    # ecdf\n",
    "    ecdf_var = [variances[:i].sum() for i in range(len(variances))]\n",
    "    fig, ax1 = plt.subplots(1,1,figsize = (20, 8))\n",
    "    ax1.plot(range(len(ecdf_var)),ecdf_var)\n",
    "    plt.xticks(range(len(ecdf_var)), range(len(ecdf_var)))\n",
    "    plt.yticks([0.1*i for i in range(11)])\n",
    "    plt.show()\n",
    "    plt.savefig(\"ola_1.png\")\n",
    "    # pca annotation and visualization\n",
    "    transformed = pca_results.transform(source_df)\n",
    "    df = pd.DataFrame([i.split('.') for i in source_df.index])\n",
    "    df.columns = [\"Patient\", \"Day\"]\n",
    "    df[\"PID\"] = source_df.index\n",
    "    for i in range(n_pc):\n",
    "        df[f\"PC{i}\"] = transformed[:, i] \n",
    "    dat_l = [visit_dict[sample] for sample in df['Patient']]\n",
    "    df['Day'] = list(dat_l)\n",
    "    \n",
    "    try:\n",
    "        with_sex_df = metadata[metadata[\"Sam_id\"].isin(df[\"Patient\"])]\n",
    "        with_sex_df = with_sex_df.dropna(subset = [\"Sex\"])\n",
    "        df = df.set_index('PID').join(with_sex_df.set_index('Sam_id')) \n",
    "    except:\n",
    "        print(\"no metadata used\")\n",
    "    \n",
    "    df['Dataset'] = ['New' if ('193' in patient) else 'Old' for patient in list(df['Patient'])]\n",
    "    fig, ax =  plt.subplots(1, 1, sharex=True, sharey=True, figsize=(20, 10))\n",
    "    #df = df.set_index('PID').join(with_ttp_df.set_index('PID_Visit'))\n",
    "    sns.scatterplot(df[\"PC0\"] , df[\"PC1\"], hue = df[\"Day\"], style = df[\"Dataset\"], s = 100,ax = ax, cmap = \"tab10\", x_jitter = True)\n",
    "    ax.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
    " \n",
    "    # TODO: add more for each category\n",
    "    fig, ax =  plt.subplots(1, 1, sharex=True, sharey=True, figsize=(20, 10))\n",
    "    # ax1.plot(range(len(ecdf_var)),ecdf_var\n",
    "    sns.scatterplot(df[\"PC0\"] , df[\"PC1\"], hue = df[\"Day\"], style = df[\"Dataset\"], s = 100,ax = ax, cmap = \"tab10\", x_jitter = True)\n",
    "    ax.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
    "    ax.set(xlabel='PC0, explained '+str(round(variances[0], 5)*100)+\"%\", ylabel='PC1, explained '+str(round(variances[1], 5)*100)+\"%\")\n",
    "    colors = [\"orange\", \"blue\", \"red\", \"green\"]\n",
    "    for index, timepoint in enumerate([\"Day_0\", \"Wk_2\", \"Mo_2\", \"Mo_6\"]):\n",
    "    # for index, timepoint in enumerate([\"Day_0\", \"Wk_2\", ]):\n",
    "        currentDF = df.loc[df['Day'] == timepoint]\n",
    "        confidence_ellipse(currentDF['PC0'], currentDF['PC1'], ax, n_std=1.5, edgecolor=colors[index])\n",
    "    plt.savefig(\"jiligala_1.png\")\n",
    "    ## add contours for two batches\n",
    "    fig, ax =  plt.subplots(1, 1, sharex=True, sharey=True, figsize=(20, 10))\n",
    "    # ax1.plot(range(len(ecdf_var)),ecdf_var)\n",
    "\n",
    "    ls_l = [\"dotted\", \"--\"]\n",
    "    sns.scatterplot(df[\"PC0\"] , df[\"PC1\"], hue = df[\"Day\"], style = df[\"Dataset\"], s = 100,ax = ax, cmap = \"tab10\", x_jitter = True)\n",
    "    ax.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
    "    ax.set(xlabel='PC0, explained '+str(round(variances[0], 5)*100)+\"%\", ylabel='PC1, explained '+str(round(variances[1], 5)*100)+\"%\")\n",
    "    for index, batch in enumerate([\"New\", 'Old']):\n",
    "        currentDF = df.loc[df['Dataset'] == batch]\n",
    "        confidence_ellipse(currentDF['PC0'], currentDF['PC1'], ax, n_std=1.5, edgecolor=\"grey\", ls=ls_l[index])\n",
    "\n",
    "    plt.savefig(\"hehe_1.png\")\n",
    "    return df        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "data_mat = pd.read_csv(\"/home/fuc/HRZE_TB/tom_organized_codes/batch_correction_PCA/1021_microbiome_batchcorrection/microbiome_merged_intersect_1023.csv\", index_col=\"Unnamed: 0\")\n",
    "data_mat = np.array(data_mat)\n",
    "meta_data = pd.read_csv(\"/home/fuc/HRZE_TB/tom_organized_codes/batch_correction_PCA/1021_microbiome_batchcorrection/intersect_metadata_1023.csv\")\n",
    "vars_use = [\"Dataset\", \"Sex\"]\n",
    "from harmony_copy import run_harmonicMic\n",
    "# from harmony import run_harmony\n",
    "# from harmony_old import run_harmony\n",
    "ho = run_harmonicMic(data_mat, meta_data, vars_use)\n",
    "res = pd.DataFrame(ho.Z_corr)\n",
    "source_df = res\n",
    "a = pd.read_csv(\"/home/fuc/HRZE_TB/tom_organized_codes/batch_correction_PCA/1021_microbiome_batchcorrection/microbiome_merged_intersect_1023.csv\", index_col=\"Unnamed: 0\")\n",
    "source_df.index = a.columns\n",
    "source_df = source_df.T\n",
    "\n",
    "\n",
    "# establish dttp and visit dicts\n",
    "Sam_id_metaorder = [sam.split(\".\")[0] for sam in meta_data.PID]\n",
    "visit_dict = dict(zip(Sam_id_metaorder, meta_data.Visit))\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data = source_df.T.to_numpy()\n",
    "scaler.fit(data)\n",
    "ss_scaled = scaler.transform(data).T\n",
    "ss_source_df = pd.DataFrame(ss_scaled, columns = source_df.columns, index=meta_data.PID_Visit)\n",
    "df = PCA_omics(ss_source_df, n_pc=30, visit_dict=visit_dict)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
